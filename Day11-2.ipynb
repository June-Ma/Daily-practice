{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb6a332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: python-dotenv in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (1.1.1)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.16-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain) (2.11.7)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain-openai) (1.101.0)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2025.7.34-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.2-cp313-cp313-macosx_15_0_arm64.whl.metadata (1.2 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.24.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.1 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m610.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl (997 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m718.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m919.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.4.16-py3-none-any.whl (375 kB)\n",
      "Downloading orjson-3.11.2-cp313-cp313-macosx_15_0_arm64.whl (115 kB)\n",
      "Downloading regex-2025.7.34-cp313-cp313-macosx_11_0_arm64.whl (285 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.24.0-cp313-cp313-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.3/640.3 kB\u001b[0m \u001b[31m798.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, tenacity, SQLAlchemy, regex, orjson, jsonpatch, tiktoken, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/13\u001b[0m [langchain]37m━━━\u001b[0m \u001b[32m12/13\u001b[0m [langchain]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.43 jsonpatch-1.33 langchain-0.3.27 langchain-core-0.3.74 langchain-openai-0.3.31 langchain-text-splitters-0.3.9 langsmith-0.4.16 orjson-3.11.2 regex-2025.7.34 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.11.0 zstandard-0.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb29dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bio Etymology Explainer (type 'quit' to exit)\n",
      "\n",
      "English: high blood pressure (hypertension)\n",
      "\n",
      "• Breakdown:\n",
      "- 高 – high; elevated (Chinese)\n",
      "- 血 – blood (Chinese)\n",
      "- 压 – pressure; to press (Chinese)\n",
      "\n",
      "• Synthesis: A condition characterised by persistently high arterial blood pressure.\n",
      "\n",
      "• Notes: \n",
      "- 血压 alone means “blood pressure.” Traditional form: 高血壓; pinyin: gāo-xuèyā.\n",
      "- Related/contrast: 低血压 – low blood pressure (hypotension).\n",
      "- English synonym “hypertension” is from Greek hyper- “over” + Latin tensio “stretching/strain.”\n",
      "\n",
      "\n",
      "• Breakdown: 肺 – lung (Chinese)\n",
      "• Breakdown: 结核 – tubercle; by extension, tuberculosis (Chinese; literally “knot/lump + kernel/hard core”; used in medical Chinese/Japanese to calque “tubercle” from Latin tuberculum)\n",
      "\n",
      "• Synthesis: Pulmonary tuberculosis — tuberculosis affecting the lungs.\n",
      "\n",
      "• Notes: \n",
      "- Examples: 结核杆菌 “tubercle bacillus” (Mycobacterium tuberculosis); 肺外结核 “extrapulmonary tuberculosis.” \n",
      "- Contrast: 肺炎 “pneumonia” (non-tuberculous lung inflammation). \n",
      "- 结核 alone often refers to TB; the literal senses of 结 and 核 point to a small hard nodule (tubercle). The calque pathway from Latin is widely assumed in East Asian medical vocabulary, though the exact coinage history may vary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bio_term_explainer.py\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1) load OPENAI_API_KEY from .env\n",
    "load_dotenv()\n",
    "\n",
    "# 2) langchain + openai chat model\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# --- a tiny dictionary of common bio morphemes (Greek/Latin) ---\n",
    "MORPHEMES = {\n",
    "    # prefixes\n",
    "    \"anti\": \"against/opposite (Greek)\",\n",
    "    \"auto\": \"self (Greek)\",\n",
    "    \"bio\": \"life (Greek)\",\n",
    "    \"brady\": \"slow (Greek)\",\n",
    "    \"cardi\": \"heart (Greek)\",\n",
    "    \"cephal\": \"head (Greek)\",\n",
    "    \"cyan\": \"blue (Greek)\",\n",
    "    \"cyto\": \"cell (Greek)\",\n",
    "    \"derm\": \"skin (Greek)\",\n",
    "    \"entero\": \"intestine (Greek)\",\n",
    "    \"erythr\": \"red (Greek)\",\n",
    "    \"gastro\": \"stomach (Greek)\",\n",
    "    \"hemi\": \"half (Greek)\",\n",
    "    \"hemo\": \"blood (Greek)\",\n",
    "    \"hepato\": \"liver (Greek)\",\n",
    "    \"hyper\": \"over/excessive (Greek)\",\n",
    "    \"hypo\": \"under/below (Greek)\",\n",
    "    \"leuko\": \"white (Greek)\",\n",
    "    \"myo\": \"muscle (Greek)\",\n",
    "    \"nephro\": \"kidney (Greek)\",\n",
    "    \"neuro\": \"nerve (Greek)\",\n",
    "    \"osteo\": \"bone (Greek)\",\n",
    "    \"peri\": \"around (Greek)\",\n",
    "    \"poly\": \"many (Greek)\",\n",
    "    \"pseudo\": \"false (Greek)\",\n",
    "    \"tachy\": \"fast (Greek)\",\n",
    "    \"therm\": \"heat (Greek)\",\n",
    "    # suffixes\n",
    "    \"algia\": \"pain (Greek)\",\n",
    "    \"ase\": \"enzyme (modern suffix, from -ase)\",\n",
    "    \"cyte\": \"cell (Greek)\",\n",
    "    \"emia\": \"blood condition (Greek)\",\n",
    "    \"genic\": \"producing/causing (Greek)\",\n",
    "    \"genesis\": \"origin/formation (Greek)\",\n",
    "    \"itis\": \"inflammation (Greek)\",\n",
    "    \"logy\": \"study of (Greek)\",\n",
    "    \"lysis\": \"breaking down (Greek)\",\n",
    "    \"oma\": \"tumour/mass (Greek)\",\n",
    "    \"osis\": \"condition/state (Greek)\",\n",
    "    \"pathy\": \"disease/feeling (Greek)\",\n",
    "    \"phage\": \"eater (Greek)\",\n",
    "    \"philia\": \"attraction/affinity (Greek)\",\n",
    "    \"phobia\": \"fear (Greek)\",\n",
    "    \"plasty\": \"moulding/surgical repair (Greek)\",\n",
    "    \"scope\": \"instrument for viewing (Greek)\",\n",
    "    \"tomy\": \"cutting/incision (Greek)\",\n",
    "}\n",
    "\n",
    "def candidate_morphemes(term: str):\n",
    "    t = term.lower()\n",
    "    hits = []\n",
    "    # try longest-first to avoid partial overlaps\n",
    "    for m in sorted(MORPHEMES.keys(), key=len, reverse=True):\n",
    "        if m in t:\n",
    "            hits.append((m, MORPHEMES[m]))\n",
    "    return hits\n",
    "\n",
    "# set up LLM\n",
    "llm = ChatOpenAI(model=\"gpt-5\", temperature=0.2)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a precise biology etymology tutor. \"\n",
    "     \"Break terms into morphemes (Greek/Latin roots/prefixes/suffixes), explain each piece, \"\n",
    "     \"note language of origin when known, and synthesise a plain-English meaning. \"\n",
    "     \"If uncertain, say so. Don’t invent folk etymologies.\"\n",
    "     \"Translate terms in other languages to English before breakdown\"),\n",
    "    (\"user\",\n",
    "     \"Term: {term}\\n\\n\"\n",
    "     \"Candidate morphemes (may be incomplete):\\n{candidates}\\n\\n\"\n",
    "     \"Step 1) Segment the term into morphemes.\\n\"\n",
    "     \"Step 2) For each part, give meaning + origin.\\n\"\n",
    "     \"Step 3) Combine into a concise definition in plain British English.\\n\"\n",
    "     \"Step 4) Add 1–2 related examples or contrasting terms when helpful.\\n\"\n",
    "     \"Output format:\\n\"\n",
    "     \"• Breakdown: <morpheme> – <meaning> (<origin>)\\n\"\n",
    "     \"• Synthesis: <one‑sentence definition>\\n\"\n",
    "     \"• Notes: <any ambiguity/caveats>\\n\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "def explain_term(term: str) -> str:\n",
    "    hits = candidate_morphemes(term)\n",
    "    if hits:\n",
    "        lines = [f\"- {m}: {desc}\" for m, desc in hits]\n",
    "        candidates = \"\\n\".join(lines)\n",
    "    else:\n",
    "        candidates = \"- (no obvious matches; proceed by best morphological judgement)\"\n",
    "    return chain.invoke({\"term\": term, \"candidates\": candidates})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Bio Etymology Explainer (type 'quit' to exit)\")\n",
    "    while True:\n",
    "        t = input(\"Term: \").strip()\n",
    "        if t.lower() in {\"quit\", \"exit\"}:\n",
    "            break\n",
    "        print()\n",
    "        print(explain_term(t))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
