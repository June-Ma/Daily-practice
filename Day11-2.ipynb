{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb6a332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: python-dotenv in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (1.1.1)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.16-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain) (2.11.7)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from langchain-openai) (1.101.0)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/envs/datasci/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2025.7.34-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.2-cp313-cp313-macosx_15_0_arm64.whl.metadata (1.2 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.24.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.1 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m610.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_openai-0.3.31-py3-none-any.whl (74 kB)\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl (997 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.1/997.1 kB\u001b[0m \u001b[31m718.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m919.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.4.16-py3-none-any.whl (375 kB)\n",
      "Downloading orjson-3.11.2-cp313-cp313-macosx_15_0_arm64.whl (115 kB)\n",
      "Downloading regex-2025.7.34-cp313-cp313-macosx_11_0_arm64.whl (285 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.24.0-cp313-cp313-macosx_11_0_arm64.whl (640 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m640.3/640.3 kB\u001b[0m \u001b[31m798.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, tenacity, SQLAlchemy, regex, orjson, jsonpatch, tiktoken, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/13\u001b[0m [langchain]37m━━━\u001b[0m \u001b[32m12/13\u001b[0m [langchain]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.43 jsonpatch-1.33 langchain-0.3.27 langchain-core-0.3.74 langchain-openai-0.3.31 langchain-text-splitters-0.3.9 langsmith-0.4.16 orjson-3.11.2 regex-2025.7.34 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.11.0 zstandard-0.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb29dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bio Etymology Explainer (structured). Type 'quit' to exit.\n",
      "\n",
      "Terminology: 低血糖\n",
      "English Translation: hypoglycaemia; low blood sugar\n",
      "\n",
      "Breakdown\n",
      "- hypo- – under, below normal (Greek) — From Greek hypo-, ‘under’. Indicates deficiency or subnormal level.\n",
      "- glyc- – sweet, sugar (Greek) — From Greek glykys ‘sweet’. Often seen as glyco-; in ‘hypoglycaemia’ the -o- before glyc- comes from hypo-.\n",
      "- -aemia – blood condition (Greek) — From Greek haima ‘blood’ + -ia. British -aemia vs US -emia.\n",
      "\n",
      "Explanation\n",
      "The Chinese term 低血糖 literally means ‘low blood sugar’. Its standard Greco‑Latin medical equivalent is hypoglycaemia: hypo- ‘below normal’ + glyc- ‘sugar’ + -aemia ‘blood condition’, denoting an abnormally low concentration of glucose in the blood.\n",
      "\n",
      "Related words\n",
      "hyperglycaemia, euglycaemia, glycaemia, hypoglycaemic\n",
      "\n",
      "\n",
      "Terminology: 低血钾\n",
      "English Translation: low blood potassium; hypokalaemia\n",
      "\n",
      "Breakdown\n",
      "- hypo- – under, below, deficient (Greek)\n",
      "- kali- – potassium (kalium) (Neo-Latin (ultimately from Arabic)) — Combining form from New Latin kalium; source of chemical symbol K; not classical Greek/Latin.\n",
      "- -aemia – blood condition (Greek) — From Greek haima ‘blood’; British spelling -aemia (US -emia).\n",
      "\n",
      "Explanation\n",
      "The Chinese term literally means “low blood potassium.” Its Greco‑Latin equivalent is hypokalaemia: hypo‑ ‘deficient’ + kali‑ ‘potassium (kalium)’ + ‑aemia ‘blood condition’, denoting a deficiency of potassium in the blood.\n",
      "\n",
      "Related words\n",
      "hyperkalaemia, hypokalaemic, hyponatraemia, hypocalcaemia, hypomagnesaemia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bio_term_explainer.py  — structured output version\n",
    "import os\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# LangChain + OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# --- morpheme hints (yours) ---\n",
    "MORPHEMES = {\n",
    "    # prefixes\n",
    "    \"anti\": \"against/opposite (Greek)\", \"auto\": \"self (Greek)\", \"bio\": \"life (Greek)\",\n",
    "    \"brady\": \"slow (Greek)\", \"cardi\": \"heart (Greek)\", \"cephal\": \"head (Greek)\",\n",
    "    \"cyan\": \"blue (Greek)\", \"cyto\": \"cell (Greek)\", \"derm\": \"skin (Greek)\",\n",
    "    \"entero\": \"intestine (Greek)\", \"erythr\": \"red (Greek)\", \"gastro\": \"stomach (Greek)\",\n",
    "    \"hemi\": \"half (Greek)\", \"hemo\": \"blood (Greek)\", \"hepato\": \"liver (Greek)\",\n",
    "    \"hyper\": \"over/excessive (Greek)\", \"hypo\": \"under/below (Greek)\", \"leuko\": \"white (Greek)\",\n",
    "    \"myo\": \"muscle (Greek)\", \"nephro\": \"kidney (Greek)\", \"neuro\": \"nerve (Greek)\",\n",
    "    \"osteo\": \"bone (Greek)\", \"peri\": \"around (Greek)\", \"poly\": \"many (Greek)\",\n",
    "    \"pseudo\": \"false (Greek)\", \"tachy\": \"fast (Greek)\", \"therm\": \"heat (Greek)\",\n",
    "    # suffixes\n",
    "    \"algia\": \"pain (Greek)\", \"ase\": \"enzyme (modern suffix, from -ase)\",\n",
    "    \"cyte\": \"cell (Greek)\", \"emia\": \"blood condition (Greek)\", \"genic\": \"producing/causing (Greek)\",\n",
    "    \"genesis\": \"origin/formation (Greek)\", \"itis\": \"inflammation (Greek)\", \"logy\": \"study of (Greek)\",\n",
    "    \"lysis\": \"breaking down (Greek)\", \"oma\": \"tumour/mass (Greek)\", \"osis\": \"condition/state (Greek)\",\n",
    "    \"pathy\": \"disease/feeling (Greek)\", \"phage\": \"eater (Greek)\", \"philia\": \"attraction/affinity (Greek)\",\n",
    "    \"phobia\": \"fear (Greek)\", \"plasty\": \"moulding/surgical repair (Greek)\", \"scope\": \"instrument for viewing (Greek)\",\n",
    "    \"tomy\": \"cutting/incision (Greek)\",\n",
    "}\n",
    "\n",
    "def candidate_morphemes(term: str):\n",
    "    t = term.lower()\n",
    "    hits = []\n",
    "    for m in sorted(MORPHEMES.keys(), key=len, reverse=True):\n",
    "        if m in t:\n",
    "            hits.append((m, MORPHEMES[m]))\n",
    "    return hits\n",
    "\n",
    "# --- strict schema ---\n",
    "class Part(BaseModel):\n",
    "    morpheme: str = Field(..., description=\"Substring/root/prefix/suffix\")\n",
    "    meaning: str = Field(..., description=\"Gloss of the morpheme\")\n",
    "    origin: Optional[str] = Field(None, description=\"Greek/Latin/other if known\")\n",
    "    note: Optional[str] = Field(None, description=\"Ambiguity/nuance if any\")\n",
    "\n",
    "class BioEtymology(BaseModel):\n",
    "    term: str\n",
    "    english_translation: str  # <= 12 words\n",
    "    breakdown: List[Part]\n",
    "    explanation: str          # one short paragraph, British English\n",
    "    related_words: List[str] = Field(default_factory=list)\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=BioEtymology)\n",
    "\n",
    "# --- LLM + prompt ---\n",
    "llm = ChatOpenAI(model=\"gpt-5\", temperature=0.2)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a precise biology etymology tutor. \"\n",
    "     \"Break terms into authentic Greek/Latin morphemes. \"\n",
    "     \"Translate non-English terms to English first, then analyse. \"\n",
    "     \"Be explicit when uncertain; avoid folk etymologies.\"),\n",
    "    (\"user\",\n",
    "     \"Term: {term}\\n\\n\"\n",
    "     \"Candidate morphemes (hints, may be incomplete):\\n{candidates}\\n\\n\"\n",
    "     \"Return ONLY JSON that matches this schema:\\n{format_instructions}\\n\\n\"\n",
    "     \"Guidelines:\\n\"\n",
    "     \"- Segment the term into morphemes.\\n\"\n",
    "     \"- For each part: meaning + origin; add 'note' if uncertain.\\n\"\n",
    "     \"- 'english_translation' ≤ 12 words, concise.\\n\"\n",
    "     \"- 'explanation' is one short paragraph in British English.\\n\"\n",
    "     \"- 'related_words' 2–6 items if sensible.\"\n",
    "    )\n",
    "])\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "def explain_term_structured(term: str) -> BioEtymology:\n",
    "    hits = candidate_morphemes(term)\n",
    "    candidates = \"\\n\".join(f\"- {m}: {desc}\" for m, desc in hits) if hits else \\\n",
    "                 \"- (no obvious matches; proceed by best morphological judgement)\"\n",
    "    return chain.invoke({\n",
    "        \"term\": term,\n",
    "        \"candidates\": candidates,\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    })\n",
    "\n",
    "# --- renderer with your fixed headings ---\n",
    "def render_fixed(result: BioEtymology) -> str:\n",
    "    lines = []\n",
    "    lines.append(f\"Terminology: {result.term}\")\n",
    "    lines.append(f\"English Translation: {result.english_translation}\\n\")\n",
    "    lines.append(\"Breakdown\")\n",
    "    for p in result.breakdown:\n",
    "        origin = f\" ({p.origin})\" if p.origin else \"\"\n",
    "        note = f\" — {p.note}\" if p.note else \"\"\n",
    "        lines.append(f\"- {p.morpheme} – {p.meaning}{origin}{note}\")\n",
    "    lines.append(\"\\nExplanation\")\n",
    "    lines.append(result.explanation.strip())\n",
    "    if result.related_words:\n",
    "        lines.append(\"\\nRelated words\")\n",
    "        lines.append(\", \".join(result.related_words))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Bio Etymology Explainer (structured). Type 'quit' to exit.\")\n",
    "    while True:\n",
    "        t = input(\"Term: \").strip()\n",
    "        if t.lower() in {\"quit\", \"exit\"}:\n",
    "            break\n",
    "        res = explain_term_structured(t)\n",
    "        print()\n",
    "        print(render_fixed(res))\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
